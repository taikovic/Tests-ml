{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Linear Regression:Normal Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data load: \n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing=fetch_california_housing()\n",
    "housing[\"data\"].shape # equal: housing.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block\\n        - HouseAge      median house age in block\\n        - AveRooms      average number of rooms\\n        - AveBedrms     average number of bedrooms\\n        - Population    block population\\n        - AveOccup      average house occupancy\\n        - Latitude      house block latitude\\n        - Longitude     house block longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttp://lib.stat.cmu.edu/datasets/\\n\\nThe target variable is the median house value for California districts.\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.target\n",
    "#!: tableau a 1 seule dim:=> le transformer en 1! vecteur colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7185181e+01]\n",
      " [ 4.3633747e-01]\n",
      " [ 9.3952334e-03]\n",
      " [-1.0711310e-01]\n",
      " [ 6.4479220e-01]\n",
      " [-4.0338000e-06]\n",
      " [-3.7813708e-03]\n",
      " [-4.2348403e-01]\n",
      " [-4.3721911e-01]]\n"
     ]
    }
   ],
   "source": [
    "m,n=housing.data.shape\n",
    "housing_data_plus_bias=np.c_[np.ones((m,1)),housing.data] #Ajout de B0 sur ttes les lignes\n",
    "\n",
    "X=tf.constant(housing_data_plus_bias,dtype=tf.float32, name=\"X\")\n",
    "y=tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "XT=tf.transpose(X)\n",
    "theta=tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)),XT),y)\n",
    "with tf.Session() as sess:\n",
    "    theta_val=theta.eval()\n",
    "print(theta_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Batch Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization of data:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "Scaler=StandardScaler()\n",
    "scaled_housing_data=Scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias=np.c_[np.ones((m,1)),scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 MSE:  12.408011\n",
      "Epoch:  100 MSE:  0.755197\n",
      "Epoch:  200 MSE:  0.5420873\n",
      "Epoch:  300 MSE:  0.5331699\n",
      "Epoch:  400 MSE:  0.5305383\n",
      "Epoch:  500 MSE:  0.5287961\n",
      "Epoch:  600 MSE:  0.52754897\n",
      "Epoch:  700 MSE:  0.5266499\n",
      "Epoch:  800 MSE:  0.52600086\n",
      "Epoch:  900 MSE:  0.5255331\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs=1000\n",
    "learning_rate=0.01\n",
    "\n",
    "# Variables Build\n",
    "X=tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32,name=\"X\")\n",
    "y=tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "theta=tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0),name=\"theta\") # cree 1 node\n",
    "\n",
    "#instruction Build\n",
    "y_pred=tf.matmul(X,theta,name=\"predictions\")\n",
    "error=y_pred - y \n",
    "mse=tf.reduce_mean(tf.square(error),name=\"mse\")\n",
    "gradients=2/m * tf.matmul(tf.transpose(X),error)# Gradients calcules!!!!\n",
    "training_op=tf.assign(theta,theta - learning_rate * gradients) #assign function cree 1 node\n",
    "\n",
    "#passons a l'execution:\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: \",epoch,\"MSE: \",mse.eval())\n",
    "        training_op.eval()# OR, sess.run(training_op)\n",
    "    best_theta=theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685523e+00],\n",
       "       [ 8.1063598e-01],\n",
       "       [ 1.2685776e-01],\n",
       "       [-2.0784086e-01],\n",
       "       [ 2.4839850e-01],\n",
       "       [-1.3083885e-03],\n",
       "       [-3.9607048e-02],\n",
       "       [-8.5861266e-01],\n",
       "       [-8.2600272e-01]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Automatic Differentiation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs=1000\n",
    "learning_rate=0.01\n",
    "\n",
    "# Variables Build\n",
    "X=tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32,name=\"X\")\n",
    "y=tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "theta=tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0),name=\"theta\") # cree 1 node\n",
    "\n",
    "#instruction Build\n",
    "y_pred=tf.matmul(X,theta,name=\"predictions\")\n",
    "error=y_pred - y \n",
    "mse=tf.reduce_mean(tf.square(error),name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient: fourni par tensorflow, vecteur a 9 composantes\n",
    "gradients=tf.gradients(mse,[theta])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 MSE:  12.408011\n",
      "Epoch:  100 MSE:  0.75519687\n",
      "Epoch:  200 MSE:  0.5420873\n",
      "Epoch:  300 MSE:  0.5331699\n",
      "Epoch:  400 MSE:  0.5305383\n",
      "Epoch:  500 MSE:  0.5287961\n",
      "Epoch:  600 MSE:  0.52754897\n",
      "Epoch:  700 MSE:  0.52664983\n",
      "Epoch:  800 MSE:  0.52600086\n",
      "Epoch:  900 MSE:  0.5255331\n",
      "Best theta:\n",
      "[[ 2.0685525e+00]\n",
      " [ 8.1063598e-01]\n",
      " [ 1.2685777e-01]\n",
      " [-2.0784083e-01]\n",
      " [ 2.4839847e-01]\n",
      " [-1.3083883e-03]\n",
      " [-3.9607048e-02]\n",
      " [-8.5861266e-01]\n",
      " [-8.2600272e-01]]\n"
     ]
    }
   ],
   "source": [
    "training_op=tf.assign(theta,theta - learning_rate * gradients)\n",
    "#passons a l'execution:\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: \",epoch,\"MSE: \",mse.eval())\n",
    "        training_op.eval()# OR, sess.run(training_op)\n",
    "    best_theta=theta.eval()\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - tensorflow GD Optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs=1000\n",
    "learning_rate=0.01\n",
    "\n",
    "# Variables Build\n",
    "X=tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32,name=\"X\")\n",
    "y=tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "theta=tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0),name=\"theta\") # cree 1 node\n",
    "\n",
    "#instruction Build\n",
    "y_pred=tf.matmul(X,theta,name=\"predictions\")\n",
    "error=y_pred - y \n",
    "mse=tf.reduce_mean(tf.square(error),name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition de l'objet fonction d'optimization:\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "# minimize objectif function: \n",
    "training_op=optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 MSE:  12.408011\n",
      "Epoch:  100 MSE:  0.75519687\n",
      "Epoch:  200 MSE:  0.5420873\n",
      "Epoch:  300 MSE:  0.5331699\n",
      "Epoch:  400 MSE:  0.5305383\n",
      "Epoch:  500 MSE:  0.5287961\n",
      "Epoch:  600 MSE:  0.52754897\n",
      "Epoch:  700 MSE:  0.52664983\n",
      "Epoch:  800 MSE:  0.52600086\n",
      "Epoch:  900 MSE:  0.5255331\n",
      "Best theta:\n",
      "[[ 2.0685525e+00]\n",
      " [ 8.1063598e-01]\n",
      " [ 1.2685777e-01]\n",
      " [-2.0784083e-01]\n",
      " [ 2.4839847e-01]\n",
      " [-1.3083883e-03]\n",
      " [-3.9607048e-02]\n",
      " [-8.5861266e-01]\n",
      " [-8.2600272e-01]]\n"
     ]
    }
   ],
   "source": [
    "#passons a l'execution:\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: \",epoch,\"MSE: \",mse.eval())\n",
    "        sess.run(training_op) #!! plus de fonction eval().\n",
    "    best_theta=theta.eval()\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - tensorflow momentum optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs=1000\n",
    "learning_rate=0.01\n",
    "\n",
    "# Variables Build\n",
    "X=tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32,name=\"X\")\n",
    "y=tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "theta=tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0),name=\"theta\") # cree 1 node\n",
    "\n",
    "#instruction Build\n",
    "y_pred=tf.matmul(X,theta,name=\"predictions\")\n",
    "error=y_pred - y \n",
    "mse=tf.reduce_mean(tf.square(error),name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition de l'objet fonction d'optimization avec l'inertie:\n",
    "optimizer=tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "# minimize objectif function: \n",
    "training_op=optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 MSE:  12.408011\n",
      "Epoch:  100 MSE:  0.5252007\n",
      "Epoch:  200 MSE:  0.5243332\n",
      "Epoch:  300 MSE:  0.5243213\n",
      "Epoch:  400 MSE:  0.52432084\n",
      "Epoch:  500 MSE:  0.524321\n",
      "Epoch:  600 MSE:  0.5243211\n",
      "Epoch:  700 MSE:  0.52432096\n",
      "Epoch:  800 MSE:  0.52432096\n",
      "Epoch:  900 MSE:  0.52432096\n",
      "Best theta:\n",
      "[[ 2.068558  ]\n",
      " [ 0.8296182 ]\n",
      " [ 0.11875144]\n",
      " [-0.26552498]\n",
      " [ 0.3056947 ]\n",
      " [-0.00450307]\n",
      " [-0.03932622]\n",
      " [-0.89988816]\n",
      " [-0.8705434 ]]\n"
     ]
    }
   ],
   "source": [
    "#passons a l'execution:\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: \",epoch,\"MSE: \",mse.eval())\n",
    "        sess.run(training_op) #!! plus de fonction eval().\n",
    "    best_theta=theta.eval()\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Substitution nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_val1: \n",
      "[[6. 7. 8.]]\n",
      "\n",
      "\n",
      "B_val2: \n",
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "# call placeholder function:\n",
    "A = tf.placeholder(tf.float32,shape=(None,3))\n",
    "B = A + 5\n",
    "# pour l'evaluation: on passe a eval() de B, un feed_dict qui precise la valeur de A\n",
    "with tf.Session():\n",
    "    B_val1=B.eval(feed_dict={A:[[1,2,3]]})\n",
    "    B_val2=B.eval(feed_dict={A:[[4,5,6],[7,8,9]]})\n",
    "print(\"B_val1: \")\n",
    "print(B_val1)\n",
    "print(\"\\n\")\n",
    "print(\"B_val2: \")\n",
    "print(B_val2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Mini-batch Gradient Descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "learning_rate=0.01\n",
    "n_epochs=10\n",
    "batch_size=100 #ce qui fait epochs total:1000\n",
    "n_batches=int(np.ceil(m/batch_size))\n",
    "\n",
    "# Variables Build\n",
    "X=tf.placeholder(tf.float32,shape=(None,n+1),name=\"X\")\n",
    "y=tf.placeholder(tf.float32,shape=(None,1),name=\"y\")\n",
    "theta=tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0),name=\"theta\") # cree 1 node\n",
    "\n",
    "#instruction Build\n",
    "y_pred=tf.matmul(X,theta,name=\"predictions\")\n",
    "error=y_pred - y \n",
    "mse=tf.reduce_mean(tf.square(error),name=\"mse\")\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op=optimizer.minimize(mse)\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_theta: \n",
      "[[ 2.0701346 ]\n",
      " [ 0.8322434 ]\n",
      " [ 0.11718354]\n",
      " [-0.25360975]\n",
      " [ 0.33584762]\n",
      " [ 0.00311589]\n",
      " [-0.01102609]\n",
      " [-0.90628386]\n",
      " [-0.8712015 ]]\n"
     ]
    }
   ],
   "source": [
    "def fetch_batch(epoch,batch_index,batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index) #eviter les memes lignes\n",
    "    indices=np.random.randint(m,size=batch_size)\n",
    "    X_batch=scaled_housing_data_plus_bias[indices]\n",
    "    y_batch=housing.target.reshape(-1,1)[indices]\n",
    "    return X_batch, y_batch\n",
    "#Execution: \n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch,y_batch=fetch_batch(epoch,batch_index,batch_size) #input\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch}) #feed_dict: passer les inputs\n",
    "    best_theta=theta.eval() #theta n'a besoin de rien pour son evaluation;\n",
    "    \n",
    "print(\"Best_theta: \")\n",
    "print(best_theta)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Save/restore models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 MSE:  9.161543\n",
      "Epoch:  100 MSE:  0.7145006\n",
      "Epoch:  200 MSE:  0.566705\n",
      "Epoch:  300 MSE:  0.5555719\n",
      "Epoch:  400 MSE:  0.5488112\n",
      "Epoch:  500 MSE:  0.5436362\n",
      "Epoch:  600 MSE:  0.5396294\n",
      "Epoch:  700 MSE:  0.5365092\n",
      "Epoch:  800 MSE:  0.5340678\n",
      "Epoch:  900 MSE:  0.5321474\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000                                                                      \n",
    "learning_rate = 0.01                                                                  \n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")            \n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")            \n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")                                      \n",
    "error = y_pred - y                                                                    \n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")                                    \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)           \n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "# Creation du Noeud Saver a la fin de la phase de construction\n",
    "# Apres la creation de tous les noeuds et variables !!!\n",
    "saver=tf.train.Saver() #ici, toutes vars et nodes sont sauvegardes:\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0 :\n",
    "            print(\"Epoch: \",epoch,\"MSE: \",mse.eval())\n",
    "            save_path=saver.save(sess,\"./tmp/my_regmodel.ckpt\") #save every 100 iters\n",
    "        sess.run(training_op)\n",
    "    best_theta=theta.eval()\n",
    "    save_path=saver.save(sess,\"./tmp/my_final_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685525 ],\n",
       "       [ 0.8874027 ],\n",
       "       [ 0.14401658],\n",
       "       [-0.34770882],\n",
       "       [ 0.36178368],\n",
       "       [ 0.00393811],\n",
       "       [-0.04269556],\n",
       "       [-0.6614528 ],\n",
       "       [-0.6375277 ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/my_final_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Restore the model:\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,\"./tmp/my_final_model.ckpt\")\n",
    "    best_theta_restored=theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(best_theta,best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut preciser la variable a sauvegarder avec son nom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver=tf.train.Saver({\"weights\":theta})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objet Saver enregistre aussi un graphe qui a le nom du fichier sauvegarder + l'extension .meta\n",
    "on peut le charger avec le graphe par defaut, comme suit: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/my_final_model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685525 ],\n",
       "       [ 0.8874027 ],\n",
       "       [ 0.14401658],\n",
       "       [-0.34770882],\n",
       "       [ 0.36178368],\n",
       "       [ 0.00393811],\n",
       "       [-0.04269556],\n",
       "       [-0.6614528 ],\n",
       "       [-0.6375277 ]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph() # graph vide mntnt\n",
    "saver=tf.train.import_meta_graph(\"./tmp/my_final_model.ckpt.meta\") # on load la structure du graph\n",
    "theta=tf.get_default_graph().get_tensor_by_name(\"theta:0\")\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    saver.restore(sess,\"./tmp/my_final_model.ckpt\") #restore l'etat du graph\n",
    "    best_theta_restored=theta.eval()\n",
    "\n",
    "best_theta_restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(best_theta,best_theta_restored)\n",
    "#on peut tjrs loader un model sans pour autant le code qui le build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 -  Visualisation du Graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
